local_mode: True # True for debug mode only
share_policy: "group" #  individual(separate) / group(division) / all(share)
evaluation_interval: 10 # evaluate model every 10 training iterations
framework: "torch"
num_workers: 1 # thread number
num_gpus: 0 # gpu to use
num_cpus: 1
num_cpus_per_worker: 1 # cpu allocate to each worker
num_gpus_per_worker: 0 # gpu allocate to each worker
checkpoint_freq: 100 # save model every 100 training iterations
checkpoint_end: True # save model at the end of the exp
restore_path: "" # load model path: 1. resume exp 2. rendering policy
stop_iters: 9999 # stop training at this iteration
stop_timesteps: 2000 # stop training at this timesteps
stop_reward: 9999 # stop training at this reward
seed: 321 # ray seed